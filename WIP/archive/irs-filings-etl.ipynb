{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5366bc0-101a-4834-905d-5d8c9392a42d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 527 irs filings data\n",
    "\n",
    "**Post Description:** Detailed walk through of data extraction and cleaning for form 8871, 8872, related entities, contributions and expenditures.\n",
    "\n",
    "**Post Categories:** Data Sourcing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e55036-f3f4-4a63-b634-18e14112cf26",
   "metadata": {
    "tags": []
   },
   "source": [
    "# What is this data?\n",
    "\n",
    "Before we get into *how* to get the data, let's spend a moment understanding why getting this data is important.  To do that we need to understand a little bit of terminology and background.\n",
    "\n",
    "### 527 Organizations\n",
    "\n",
    "A 527 organization is created primarily to influence politics.  They are tax-exempt political organizations that were created to influence selection, nomination, election, appointment, or defeat of candidates to federal, state, or local public office.  \n",
    "\n",
    "### What data does the IRS provide\n",
    "\n",
    "The IRS provides form 8871 and 8872 and attachments to those forms.  These are:\n",
    "\n",
    "+ Form 8871: Top level information about a 527 organization\n",
    "    + Type \"D\": Directors and Officers\n",
    "    + Type \"R\": Related Entities\n",
    "    + Type \"E\": Election Authority Identification number(s)\n",
    "+ Form 8872: Top level main form data\n",
    "    + Type \"A\": Schedule A data (Itemized Contributions) for 8872\n",
    "    + Type \"B\": Schedule B data (Itemized Expenditures) for 8872\n",
    "    \n",
    "Clearly these are important to understading financial influence in politics and a core requirement to understand it well.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399112cf-77c5-43c8-8832-ce3d00115fd5",
   "metadata": {},
   "source": [
    "# Data Pull"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b85d0d8-d0fe-42ac-914f-7a7f327b1c11",
   "metadata": {},
   "source": [
    ">Credit: [This repo]( https://github.com/sahilchinoy/django-irs-filings) written by [Sahil Chinoy](https://sahilchinoy.com/) was very helpful in writing this code.  I changed a lot, but left a lot the same.  The irs has changed significantly since the code was written, but it was a huge help anyway as the general structure of the files is the same."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc255007-c201-4e12-b05b-ee978f99338e",
   "metadata": {},
   "source": [
    "We will now walk through the code to download and get the data into a usable format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216f93ea-65c7-48bc-b99c-636e273c6043",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1c66b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collapse-hide\n",
    "# System Libs\n",
    "import os, sys, shutil\n",
    "from pathlib import Path\n",
    "\n",
    "#File Libs\n",
    "import csv, io, zipfile, pickle\n",
    "\n",
    "# Data Download\n",
    "import requests\n",
    "\n",
    "# Data Processing and Transformation\n",
    "import pandas as pd \n",
    "from collections import defaultdict\n",
    "def def_value(): return [] # this is for a default dict we use later\n",
    "from fastcore.all import L\n",
    "from datetime import datetime\n",
    "\n",
    "# Vinculum Re-Usable Utilities\n",
    "from download_utils import unzip_file, download_file\n",
    "\n",
    "# jupyter Utils\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# Configure Logging for Jupyter - This is to make transition to modules easier\n",
    "import logging\n",
    "logger = logging.getLogger(name=\"jupyter\")\n",
    "if len(logger.handlers) == 0: logger.addHandler(logging.StreamHandler(stream=sys.stdout))\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc07a809",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Download and Extract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b19e6e6-da86-49d9-810f-4f425cb65984",
   "metadata": {},
   "source": [
    "This step is very simple so we won't spend much time on it.  It covers 3 things:\n",
    "+ Download\n",
    "+ Unzip\n",
    "+ Flatten directory structure out\n",
    "\n",
    "We imported the download_file and unzip_file functions from our utility functions.  I will not cover those here as they are standard download and unzipping and not unique to this dataset.  Feel free to check those out at our github repository if you wouldb like.\n",
    "\n",
    "```python\n",
    "from download_utils import unzip_file, download_file\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2666894f-4a04-4e43-985b-f07cb7026f3f",
   "metadata": {},
   "source": [
    "We need a simple function to clean the directories.  This is because once unzipped, the data file is 6 directories deep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f36d9344",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_527(zip_path,extract_path,final_path):\n",
    "    logger.info('Cleaning up archive...')\n",
    "    shutil.move(f\"{extract_path}/var/IRS/data/scripts/pofd/download/FullDataFile.txt\",final_path)\n",
    "    shutil.rmtree(extract_path)\n",
    "    os.remove(zip_path)\n",
    "    logger.info(f\"FINAL RAW DATA FILE RELATIVE PATH: {final_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afaa8af1-54c4-44c2-932b-de699a650792",
   "metadata": {},
   "source": [
    "After that all we need to do is Download unzip and clean.  This step is pretty straightforward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33e87783",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(url, zip_path,extract_path,final_path):\n",
    "    download_file(url,zip_path)\n",
    "    unzip_file(zip_path,extract_path)\n",
    "    clean_527(zip_path,extract_path,final_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a5e4ca-97e6-4088-ade2-499e626e470e",
   "metadata": {},
   "source": [
    "Run all that and we are done with this step and have the file unzipped and where we want it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4865858",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://forms.irs.gov/app/pod/dataDownload/fullData'\n",
    "base_dir = Path(\"./data/irs-filings\")\n",
    "zip_path = (base_dir/'data.zip')\n",
    "extract_path = (base_dir/'unzipped/')\n",
    "final_path = (base_dir/'raw_FullDataFile.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f2a5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_data(zip_path,extract_path,final_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b8a6ba1-63fb-48f1-99fe-1a4c2b434905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw_FullDataFile.txt\n"
     ]
    }
   ],
   "source": [
    "!ls data/irs-filings/ | grep txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af87a1bf-d249-4e5a-9616-393896eb0252",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Clean and Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005d0f71-ece4-41da-b05a-eaccc5a12c54",
   "metadata": {
    "tags": []
   },
   "source": [
    "The next step is more unique to this dataset.  This is more complex due to the IRS practice of storing multiple types of data in the same pipe delimited file (with differing numbers of columns).  In a normal \"relational\" structure, this would be multiple different files.\n",
    "\n",
    "This means we need to parse row by row to determine what type of row it is to know how to process it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece34d29-c674-427b-b8c9-0b298a75da65",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Mapping\n",
    "\n",
    "The first step is to get a mapping of the different record types.  I created this by converting the IRS data dictionary from MS Word into an excel format so that I could read in and get field names and data types for each value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f090bb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mapping_file(fname, record_types = [\"1\",\"D\",\"R\",\"E\",\"2\",\"A\",\"B\"]):\n",
    "    mappings = {}\n",
    "    for r in record_types: mappings[r] = pd.read_excel(mappings_path,sheet_name=r)\n",
    "    return mappings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17fa5db-78f0-4c46-888e-896c16cc6e49",
   "metadata": {},
   "source": [
    "When we run this for each type of row we get fiel name and type "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "275d3f8d-129f-4b99-8119-b75a522328ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>field_name</th>\n",
       "      <th>field_type</th>\n",
       "      <th>position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>record_type</td>\n",
       "      <td>Record Type</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>form_id_number</td>\n",
       "      <td>Form ID Number</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eain_id</td>\n",
       "      <td>EAIN ID</td>\n",
       "      <td>N</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>election_authority_id_number</td>\n",
       "      <td>ELECTION AUTHORITY ID NUMBER</td>\n",
       "      <td>C</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>state_issued</td>\n",
       "      <td>STATE_ISSUED</td>\n",
       "      <td>C</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     model_name                    field_name field_type  \\\n",
       "0                   record_type                   Record Type          C   \n",
       "1                form_id_number                Form ID Number          N   \n",
       "2                       eain_id                       EAIN ID          N   \n",
       "3  election_authority_id_number  ELECTION AUTHORITY ID NUMBER          C   \n",
       "4                  state_issued                  STATE_ISSUED          C   \n",
       "\n",
       "   position  \n",
       "0         0  \n",
       "1         1  \n",
       "2         2  \n",
       "3         3  \n",
       "4         4  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mappings_path = Path(\"DataConfigs/irs-filings/mappings.xlsx\")\n",
    "load_mapping_file(mappings_path)['E']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b966edfa-e8b4-400e-8b33-b7df75e56092",
   "metadata": {},
   "source": [
    "Next, we convert the information we need from this into so we can look it up faster as we are parsing the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5185afa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mappings(mapping_file):\n",
    "    record_types = L(mapping_file.keys())\n",
    "    mappings = {}\n",
    "    for record_type in record_types:\n",
    "        cols = L(o for o in mapping_file[record_type].columns)\n",
    "        mapping = {}\n",
    "        for row in mapping_file[record_type].values:\n",
    "            mapping[row[cols.index('position')]] = (row[cols.index('model_name')],row[cols.index('field_type')])\n",
    "        mappings[record_type] = mapping\n",
    "    return mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a22ccd64-c544-4ff5-b154-b7ad635ecdd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: ('record_type', 'C'),\n",
       " 1: ('form_id_number', 'N'),\n",
       " 2: ('eain_id', 'N'),\n",
       " 3: ('election_authority_id_number', 'C'),\n",
       " 4: ('state_issued', 'C')}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mappings = build_mappings(load_mapping_file(mappings_path))\n",
    "mappings['E']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c52483f-d162-4997-8122-abc96a876abe",
   "metadata": {},
   "source": [
    "## Parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1141116f-d934-4dbd-885e-adbfb3ff05a2",
   "metadata": {},
   "source": [
    "Finally we are onto the meat of this, which is parsing the file.\n",
    "\n",
    "Firse we create a function to parse each cell.  This uses the mapping to set the appropriate datatype and truncate as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a81d6b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_cell(cell, cell_type,NULL_TERMS = ['N/A','NOT APPLICABLE','NA','NONE','NOT APPLICABE','NOT APLICABLE','N A','N-A']):\n",
    "    if cell_type == 'D': cell = datetime.strptime(cell, '%Y-%m-%d %H:%M:%S')\n",
    "    elif cell_type == 'I': cell = int(cell)\n",
    "    elif cell_type == 'N': cell = float(cell)\n",
    "    else:\n",
    "        cell = cell.upper()\n",
    "        if len(cell) > 50: cell = cell[0:50]\n",
    "        if not cell or cell in NULL_TERMS: cell = None\n",
    "    return cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b1b33a-c3a3-4eaf-8cc7-faf9a3fcade3",
   "metadata": {},
   "source": [
    "Then we go through each row and clean the cell and append it to a dictionary.  This was for each row we have each field name cleaned and the value associated with it cleaned per our data dictionary/mapping file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8dffc13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_row(row, mapping):\n",
    "    fields = mapping\n",
    "    parsed_row = {}\n",
    "    for i, cell in enumerate(row[0:len(fields)]):\n",
    "        field_name, field_type = fields[i]\n",
    "        parsed_cell = clean_cell(cell, field_type)\n",
    "        parsed_row[field_name] = parsed_cell\n",
    "    return parsed_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "492ea6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This just allows us to have a visual indicator of how much longer it will take\n",
    "def file_len(fname):\n",
    "    with open(fname) as f:\n",
    "        for i, l in enumerate(f): pass\n",
    "    return i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3a0671f-4ec7-4ff5-806e-646a679e6867",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv.field_size_limit(sys.maxsize)\n",
    "final_path = (base_dir/'raw_FullDataFile.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3317ef68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(final_path,mappings):\n",
    "    with io.open(final_path, 'r', encoding='ISO-8859-1') as raw_file:\n",
    "        reader = csv.reader(raw_file, delimiter='|')\n",
    "\n",
    "        def def_value(): return []\n",
    "        records = defaultdict(def_value)\n",
    "        file_length = file_len(final_path)\n",
    "        start_time = datetime.now()\n",
    "        for i,row in enumerate(reader):\n",
    "            try:\n",
    "                form_type = str(row[0])\n",
    "                if form_type in mappings.keys(): \n",
    "                    parsed_row = parse_row(row, mappings[form_type])\n",
    "                    records[form_type].append(parsed_row)\n",
    "                elif form_type in (\"H\",\"F\"): logger.info(row)\n",
    "            except IndexError:\n",
    "                if row != '\\n': records[\"error_idxs\"].append(i)\n",
    "            if i%10000 ==0:\n",
    "                clear_output(wait=True)\n",
    "                elapsed = datetime.now()-start_time\n",
    "                time_per = elapsed/max(i,1)\n",
    "                logger.info(f\"{i} of {file_length} | {round((i/file_length)*100,2)}% | Elapsed={elapsed} | Time Per={time_per} | Remaining={time_per*(file_length-i)}\")\n",
    "    pickle.dump(dict(records), open('data/irs-filings/processed_lists.pickle', \"wb\" ) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63a9323b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# mappings_path = Path(\"DataConfigs/irs-filings/mappings.xlsx\")\n",
    "# mappings = build_mappings(load_mapping_file(mappings_path))\n",
    "# process_file(final_path,mappings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295dcfed",
   "metadata": {},
   "source": [
    "# Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9195ecce",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/irs-filings/processed_lists.pickle', 'rb') as handle:\n",
    "    records = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a9b994",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afbbd838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[dict_keys(['record_type', 'form_type', 'form_id_number', 'initial_report_indicator', 'amended_report_indicator', 'final_report_indicator', 'ein', 'organization_name', 'mailing_address_1', 'mailing_address_2', 'mailing_address_city', 'mailing_address_state', 'mailing_address_zip_code', 'mailing_address_zip_ext', 'e_mail_address', 'established_date', 'custodian_name', 'custodian_address_1', 'custodian_address_2', 'custodian_address_city', 'custodian_address_state', 'custodian_address_zip_code', 'custodian_address_zip_ext', 'contact_person_name', 'contact_address_1', 'contact_address_2', 'contact_address_city', 'contact_address_state', 'contact_address_zip_code', 'contact_address_zip_ext', 'business_address_1', 'business_address_2', 'business_address_city', 'business_address_state', 'business_address_zip_code', 'business_address_zip_ext', 'exempt_8872_indicator', 'exempt_state', 'exempt_990_indicator', 'purpose', 'material_change_date', 'insert_datetime', 'related_entity_bypass', 'eain_bypass']),\n",
       " dict_keys(['record_type', 'form_id_number', 'director_id', 'org_name', 'ein', 'entity_name', 'entity_title', 'entity_address_1', 'entity_address_2', 'entity_address_city', 'entity_address_st', 'entity_address_zip_code', 'entity_address_zip_code_ext']),\n",
       " dict_keys(['record_type', 'form_id_number', 'entity_id', 'org_name', 'ein', 'entity_name', 'entity_relationship', 'entity_address_1', 'entity_address_2', 'entity_address_city', 'entity_address_st', 'entity_address_zip_code', 'entity_address_zip_ext']),\n",
       " dict_keys(['record_type', 'form_id_number', 'eain_id', 'election_authority_id_number', 'state_issued']),\n",
       " dict_keys(['record_type', 'form_type', 'form_id_number', 'period_begin_date', 'period_end_date', 'initial_report_indicator', 'amended_report_indicator', 'final_report_indicator', 'change_of_address_indicator', 'organization_name', 'ein', 'mailing_address_1', 'mailing_address_2', 'mailing_address_city', 'mailing_address_state', 'mailing_address_zip_code', 'mailing_address_zip_ext', 'e_mail_address', 'org_formation_date', 'custodian_name', 'custodian_address_1', 'custodian_address_2', 'custodian_address_city', 'custodian_address_state', 'custodian_address_zip_code', 'custodian_address_zip_ext', 'contact_person_name', 'contact_address_1', 'contact_address_2', 'contact_address_city', 'contact_address_state', 'contact_address_zip_code', 'contact_address_zip_ext', 'business_address_1', 'business_address_2', 'business_address_city', 'business_address_state', 'business_address_zip_code', 'business_address_zip_ext', 'qtr_indicator', 'monthly_rpt_month', 'pre_elect_type', 'pre_or_post_elect_date', 'pre_or_post_elect_state', 'sched_a_ind', 'total_sched_a', 'sched_b_ind', 'total_sched_b', 'insert_datetime']),\n",
       " dict_keys(['record_type', 'form_id_number', 'sched_a_id', 'org_name', 'ein', 'contributor_name', 'contributor_address_1', 'contributor_address_2', 'contributor_address_city', 'contributor_address_state', 'contributor_address_zip_code', 'contributor_address_zip_ext', 'contributor_employer', 'contribution_amount', 'contributor_occupation', 'agg_contribution_ytd', 'contribution_date']),\n",
       " dict_keys(['record_type', 'form_id_number', 'sched_b_id', 'org_name', 'ein', 'reciepient_name', 'reciepient_address_1', 'reciepient_address_2', 'reciepient_address_city', 'reciepient_address_st', 'reciepient_address_zip_code', 'reciepient_address_zip_ext', 'reciepient_employer', 'expenditure_amount', 'recipient_occupation', 'expenditure_date', 'expenditure_purpose'])]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[records[key][0].keys() for key in records.keys() if key != 'error_idxs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb3a030",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_names = {'1':'8871_form_record',\n",
    "                'D':'8871_directors_officers',\n",
    "                'R':'8871_related_entities',\n",
    "                'E':'8871_eain',\n",
    "                '2':'8872_form_record',\n",
    "                'A':'8872_schedule_a',\n",
    "                'B':'8872_schedule_b',\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5ebb0abb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "237"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors = L(records['error_idxs'])\n",
    "new_errors = []\n",
    "with open(\"data/irs-filings/raw_FullDataFile.txt\") as fp:\n",
    "    for i, line in enumerate(fp):\n",
    "        if i in errors:\n",
    "            if line == '\\n': continue\n",
    "            new_errors.append((i,line))\n",
    "len(new_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "09dd9a8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('data/irs-filings/raw_FullDataFile.txt')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(base_dir/'raw_FullDataFile.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7541499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conn = sqlite3.connect('./data/irs-filings/db.sqlite')for k in records.keys():\n",
    "#     if k=='error_idxs': continue\n",
    "#     print(f\"type_{k} writings...\")\n",
    "#     pd.DataFrame(records[k]).to_sql(f\"type_{k}\",conn,if_exists=\"replace\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "512725bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.read_sql(f\"select * from type_A limit 25\",conn).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2accf9d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4a7f1ebfaddf68725d4796cad0ddde8ff8a752ccfc0551e8ea50b332ad07ecb7"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
