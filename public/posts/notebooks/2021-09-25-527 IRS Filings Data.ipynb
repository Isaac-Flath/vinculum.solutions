{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a151f5c5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 527 IRS filings data\n",
    "\n",
    "**Post Description:** Detailed walk through of data extraction and cleaning for form 8871, 8872, related entities, contributions and expenditures.\n",
    "\n",
    "**Post Categories:** Data Sourcing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337921e3",
   "metadata": {
    "tags": []
   },
   "source": [
    "# What is this data?\n",
    "\n",
    "Before we get into *how* to get the data, let's spend a moment understanding why getting this data is important.  To do that we need to understand a little bit of terminology and background.\n",
    "\n",
    "### 527 Organizations\n",
    "\n",
    "A 527 organization is created primarily to influence politics.  They are tax-exempt political organizations that were created to influence selection, nomination, election, appointment, or defeat of candidates to federal, state, or local public office.  \n",
    "\n",
    "### What data does the IRS provide\n",
    "\n",
    "The IRS provides form 8871 and 8872 and attachments to those forms.  These are:\n",
    "\n",
    "+ Form 8871: Top level information about a 527 organization\n",
    "    + Type \"D\": Directors and Officers\n",
    "    + Type \"R\": Related Entities\n",
    "    + Type \"E\": Election Authority Identification number(s)\n",
    "+ Form 8872: Top level main form data\n",
    "    + Type \"A\": Schedule A data (Itemized Contributions) for 8872\n",
    "    + Type \"B\": Schedule B data (Itemized Expenditures) for 8872\n",
    "    \n",
    "Clearly these are important to understading financial influence in politics and a core requirement to understand it well.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3736bbe8",
   "metadata": {},
   "source": [
    "# Data Pull"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0253634a",
   "metadata": {},
   "source": [
    ">Credit: [This repo]( https://github.com/sahilchinoy/django-irs-filings) written by [Sahil Chinoy](https://sahilchinoy.com/) was very helpful in writing this code.  I changed a lot, but left a lot the same.  The irs has changed significantly since the code was written, but it was a huge help anyway as the general structure of the files is the same."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1daea19",
   "metadata": {},
   "source": [
    "We will now walk through the code to download and get the data into a usable format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1565247e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb8c9f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System Libs\n",
    "import os, sys, shutil\n",
    "from pathlib import Path\n",
    "\n",
    "#File Libs\n",
    "import csv, io, pickle\n",
    "\n",
    "# Data Processing and Transformation\n",
    "import pandas as pd \n",
    "from collections import defaultdict\n",
    "def def_value(): return [] # this is for a default dict we use later\n",
    "from fastcore.all import L\n",
    "from datetime import datetime\n",
    "\n",
    "# Vinculum Re-Usable Utilities\n",
    "from download_utils import unzip_file, download_file\n",
    "\n",
    "# jupyter Utils\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# Configure Logging for Jupyter - This is to make transition to modules easier\n",
    "import logging\n",
    "logger = logging.getLogger(name=\"jupyter\")\n",
    "if len(logger.handlers) == 0: logger.addHandler(logging.StreamHandler(stream=sys.stdout))\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3577bc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Download and Extract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed029c6",
   "metadata": {},
   "source": [
    "This step is very simple so we won't spend much time on it.  It covers 3 things:\n",
    "+ Download\n",
    "+ Unzip\n",
    "+ Flatten directory structure out\n",
    "\n",
    "We imported the download_file and unzip_file functions from our utility functions.  I will not cover those here as they are standard download and unzipping and not unique to this dataset.  Feel free to check those out at our github repository if you wouldb like.\n",
    "\n",
    "```python\n",
    "from download_utils import unzip_file, download_file\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00f0a8f",
   "metadata": {},
   "source": [
    "We need a simple function to clean the directories.  This is because once unzipped, the data file is 6 directories deep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bb6749c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_527(zip_path,extract_path,final_path):\n",
    "    logger.info('Cleaning up archive...')\n",
    "    shutil.move(f\"{extract_path}/var/IRS/data/scripts/pofd/download/FullDataFile.txt\",final_path)\n",
    "    shutil.rmtree(extract_path)\n",
    "    os.remove(zip_path)\n",
    "    logger.info(f\"FINAL RAW DATA FILE RELATIVE PATH: {final_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08e7027",
   "metadata": {},
   "source": [
    "After that all we need to do is Download unzip and clean.  This step is pretty straightforward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "721afa07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(url, zip_path,extract_path,final_path):\n",
    "    download_file(url,zip_path)\n",
    "    unzip_file(zip_path,extract_path)\n",
    "    clean_527(zip_path,extract_path,final_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40693b3",
   "metadata": {},
   "source": [
    "Run all that and we are done with this step and have the file unzipped and where we want it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8eb34a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://forms.irs.gov/app/pod/dataDownload/fullData'\n",
    "base_dir = Path(\"./data/irs-filings\")\n",
    "zip_path = (base_dir/'data.zip')\n",
    "extract_path = (base_dir/'unzipped/')\n",
    "final_path = (base_dir/'raw_FullDataFile.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339b3487",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_data(zip_path,extract_path,final_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8dd8e2cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw_FullDataFile.txt\n"
     ]
    }
   ],
   "source": [
    "!ls data/irs-filings/ | grep txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c190317f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Clean and Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542d165f",
   "metadata": {
    "tags": []
   },
   "source": [
    "The next step is more unique to this dataset.  This is more complex due to the IRS practice of storing multiple types of data in the same pipe delimited file (with differing numbers of columns).  In a normal \"relational\" structure, this would be multiple different files.\n",
    "\n",
    "This means we need to parse row by row to determine what type of row it is to know how to process it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016c1cd6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Mapping\n",
    "\n",
    "The first step is to get a mapping of the different record types.  I created this by converting the IRS data dictionary from MS Word into an excel format so that I could read in and get field names and data types for each value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ebb02e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mapping_file(fname, record_types = [\"1\",\"D\",\"R\",\"E\",\"2\",\"A\",\"B\"]):\n",
    "    mappings = {}\n",
    "    for r in record_types: mappings[r] = pd.read_excel(mappings_path,sheet_name=r)\n",
    "    return mappings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe28e047",
   "metadata": {},
   "source": [
    "When we run this for each type of row we get fiel name and type "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1392a6ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>field_name</th>\n",
       "      <th>field_type</th>\n",
       "      <th>position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>record_type</td>\n",
       "      <td>Record Type</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>form_id_number</td>\n",
       "      <td>Form ID Number</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eain_id</td>\n",
       "      <td>EAIN ID</td>\n",
       "      <td>N</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>election_authority_id_number</td>\n",
       "      <td>ELECTION AUTHORITY ID NUMBER</td>\n",
       "      <td>C</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>state_issued</td>\n",
       "      <td>STATE_ISSUED</td>\n",
       "      <td>C</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     model_name                    field_name field_type  \\\n",
       "0                   record_type                   Record Type          C   \n",
       "1                form_id_number                Form ID Number          N   \n",
       "2                       eain_id                       EAIN ID          N   \n",
       "3  election_authority_id_number  ELECTION AUTHORITY ID NUMBER          C   \n",
       "4                  state_issued                  STATE_ISSUED          C   \n",
       "\n",
       "   position  \n",
       "0         0  \n",
       "1         1  \n",
       "2         2  \n",
       "3         3  \n",
       "4         4  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mappings_path = Path(\"DataConfigs/irs-filings/mappings.xlsx\")\n",
    "load_mapping_file(mappings_path)['E']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db762ffe",
   "metadata": {},
   "source": [
    "Next, we convert the information we need from this into so we can look it up faster as we are parsing the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0b09b98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mappings(mapping_file):\n",
    "    record_types = L(mapping_file.keys())\n",
    "    mappings = {}\n",
    "    for record_type in record_types:\n",
    "        cols = L(o for o in mapping_file[record_type].columns)\n",
    "        mapping = {}\n",
    "        for row in mapping_file[record_type].values:\n",
    "            mapping[row[cols.index('position')]] = (row[cols.index('model_name')],row[cols.index('field_type')])\n",
    "        mappings[record_type] = mapping\n",
    "    return mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "167ad417",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: ('record_type', 'C'),\n",
       " 1: ('form_id_number', 'N'),\n",
       " 2: ('eain_id', 'N'),\n",
       " 3: ('election_authority_id_number', 'C'),\n",
       " 4: ('state_issued', 'C')}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mappings = build_mappings(load_mapping_file(mappings_path))\n",
    "mappings['E']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ccadd0b",
   "metadata": {},
   "source": [
    "## Parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d3a6c3",
   "metadata": {},
   "source": [
    "Finally we are onto the meat of this, which is parsing the file.\n",
    "\n",
    "Firse we create a function to parse each cell.  This uses the mapping to set the appropriate datatype and truncate as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9fdb47a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_cell(cell, cell_type,NULL_TERMS = ['N/A','NOT APPLICABLE','NA','NONE','NOT APPLICABE','NOT APLICABLE','N A','N-A']):\n",
    "    if cell_type == 'D': cell = datetime.strptime(cell, '%Y-%m-%d %H:%M:%S')\n",
    "    elif cell_type == 'I': cell = int(cell)\n",
    "    elif cell_type == 'N': cell = float(cell)\n",
    "    else:\n",
    "        cell = cell.upper()\n",
    "        if len(cell) > 50: cell = cell[0:50]\n",
    "        if not cell or cell in NULL_TERMS: cell = None\n",
    "    return cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b69f58a",
   "metadata": {},
   "source": [
    "Then we go through each row and clean the cell and append it to a dictionary.  This was for each row we have each field name cleaned and the value associated with it cleaned per our data dictionary/mapping file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "daf51fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_row(row, mapping):\n",
    "    fields = mapping\n",
    "    parsed_row = {}\n",
    "    for i, cell in enumerate(row[0:len(fields)]):\n",
    "        field_name, field_type = fields[i]\n",
    "        parsed_cell = clean_cell(cell, field_type)\n",
    "        parsed_row[field_name] = parsed_cell\n",
    "    return parsed_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e9c4ed50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This just allows us to have a visual indicator of status of parsing\n",
    "def file_len(fname):\n",
    "    with open(fname) as f:\n",
    "        for i, l in enumerate(f): pass\n",
    "    return i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "540227ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(final_path,mappings):\n",
    "    with io.open(final_path, 'r', encoding='ISO-8859-1') as raw_file:\n",
    "        \n",
    "        # initialize variables\n",
    "        def def_value(): return []\n",
    "        records = defaultdict(def_value)\n",
    "        file_length = file_len(final_path)\n",
    "        start_time = datetime.now()\n",
    "        \n",
    "        # Parse File\n",
    "        reader = csv.reader(raw_file, delimiter='|')\n",
    "        for i,row in enumerate(reader): # Row by Row\n",
    "            try:\n",
    "                form_type = str(row[0]) # Check recort type for the row\n",
    "                if form_type in mappings.keys(): # Ensure record type is in mapping\n",
    "                    parsed_row = parse_row(row, mappings[form_type]) # Parse row using function above\n",
    "                    records[form_type].append(parsed_row) # Save parsed row in list\n",
    "                elif form_type in (\"H\",\"F\"): logger.info(row)\n",
    "            except IndexError:\n",
    "                if row != '\\n': records[\"error_idxs\"].append(i) # Append any erroneus lines to a list\n",
    "                \n",
    "            # Print out progress information and estimated time remaining\n",
    "            if i%10000 ==0:\n",
    "                clear_output(wait=True)\n",
    "                elapsed = datetime.now()-start_time\n",
    "                time_per = elapsed/max(i,1)\n",
    "                logger.info(f\"{i} of {file_length} | {round((i/file_length)*100,2)}% | Elapsed={elapsed} | Time Per={time_per} | Remaining={time_per*(file_length-i)}\")\n",
    "    \n",
    "    # Save parsed data\n",
    "    pickle.dump(dict(records), open('data/irs-filings/processed_lists.pickle', \"wb\" ) )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9808913",
   "metadata": {},
   "source": [
    "We can run all that and we have our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6859f1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "mappings_path = Path(\"DataConfigs/irs-filings/mappings.xlsx\")\n",
    "mappings = build_mappings(load_mapping_file(mappings_path))\n",
    "process_file(final_path,mappings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7b7f6d",
   "metadata": {},
   "source": [
    "# Look at the output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00aa2f2",
   "metadata": {},
   "source": [
    "In this tutorial we will not load the data into the graph database, but there will be a blog post on how we load data into it in the future.  For now, let's make sure the data looks good and look at a couple very basic things here in python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ba15af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/irs-filings/processed_lists.pickle', 'rb') as handle:\n",
    "    records = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30e1a00",
   "metadata": {},
   "source": [
    "Let's start with seeing how many organizations some of our top directors and officers are involved with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8c9d309e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity_name</th>\n",
       "      <th>org_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>J. RICHARD EICHMAN</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KINDE DURKEE</td>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SHAWNDA DEANE</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LAURA ANN STEPHEN</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NANCY H. WATKINS</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          entity_name  org_name\n",
       "0  J. RICHARD EICHMAN       241\n",
       "1        KINDE DURKEE       203\n",
       "2       SHAWNDA DEANE       181\n",
       "3   LAURA ANN STEPHEN       172\n",
       "4    NANCY H. WATKINS       166"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directorsdf = pd.DataFrame(records['D'])\n",
    "topdirectors = directorsdf[['entity_name','org_name']].groupby('entity_name').nunique().sort_values('org_name',ascending=False).head().reset_index()\n",
    "topdirectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9994e06",
   "metadata": {},
   "source": [
    "When we look we see the top 5 are all in over 150 organizations!   I wonder how they split their time between so many different companies...\n",
    "\n",
    ">Note:  You may recognize the name Kinda Durkee.  It was widely reported that she embezzled millions and agreed to an 8 year sentence for her crimes.\n",
    "\n",
    "Let's take a look at them to see what they do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5faee6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter for top directors\n",
    "topdirectors = directorsdf[directorsdf.entity_name.isin(topdirectors.entity_name)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0339bb84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record_type</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entity_title</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TREASURER</th>\n",
       "      <td>1058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ASSISTANT TREASURER</th>\n",
       "      <td>303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DEPUTY TREASURER</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ASSITANT TREASURER</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SECRETARY/TREASURER</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     record_type\n",
       "entity_title                    \n",
       "TREASURER                   1058\n",
       "ASSISTANT TREASURER          303\n",
       "DEPUTY TREASURER              13\n",
       "ASSITANT TREASURER            10\n",
       "SECRETARY/TREASURER            8"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get count of titles\n",
    "titles = topdirectors[['entity_title','record_type']].groupby('entity_title').count()\n",
    "titles.sort_values('record_type', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c2adc8",
   "metadata": {},
   "source": [
    "We can see in basically these are all money people in all the orgs they are in.  Let's see how much crossover there is with multiple of these individuals being at the same organization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ee87079b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12198067632850242"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orgs = topdirectors[['ein','entity_name']].groupby('ein').nunique()\n",
    "(orgs.entity_name > 1).sum()/(orgs.entity_name>0).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb7d991",
   "metadata": {},
   "source": [
    "Out of the top 5 names we see that in over 12% of the organizations they are a part of at least 1 of the other 4 are involved as a director or officer in that org as well.  This means that if 1 of these 5 individuals are an officer at one of these political organizations, there's about 1/8 chance at least 1 other of them is involved as an officer as well as well.\n",
    "\n",
    "What if we expanded this to include related entities?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "78f08e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get director table for join\n",
    "directorjoin = topdirectors[['org_name','entity_name']]\n",
    "directorjoin.columns = ['org_name','director_name']\n",
    "\n",
    "# get related entities table for join\n",
    "relateddf = pd.DataFrame(records['R'])\n",
    "relatedjoin = relateddf[['org_name','entity_name']]\n",
    "relatedjoin.columns = ['org_name','related_org']\n",
    "\n",
    "# Join tables\n",
    "related = pd.merge(directorjoin,relatedjoin,how='left',left_on='org_name',right_on='org_name')[['related_org','director_name']]\n",
    "related = related[~related.related_org.isnull()]\n",
    "related.columns = ['org_name','director_name']\n",
    "\n",
    "relatedtopdirectors =  pd.concat([related,directorjoin])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6b28e5",
   "metadata": {},
   "source": [
    "Now let's run the same thing as above to see if the percentage move is we inlcude the directors relationships not just to the orgs they are a part of, but of orgs related to those as well.\n",
    "\n",
    "How much overlap do we see?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "e1b2513a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17130044843049327"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orgs = relatedtopdirectors[['org_name','director_name']].groupby('org_name').nunique().reset_index()\n",
    "(orgs.director_name > 1).sum()/(orgs.director_name>0).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5864d1a9",
   "metadata": {},
   "source": [
    "Up to 17%, meaning if one of these individuals is involved in an organization there is a greater than 1/6 chance that one of the other top 4 individuals are involved in that organization or a related organization.  \n",
    "\n",
    "This may or may not be meaningful depending on what is found as we dig deeper, but I hope you enjoyed seeing a cursory sneak peak at just a couple of the many data points the IRS data includes."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4a7f1ebfaddf68725d4796cad0ddde8ff8a752ccfc0551e8ea50b332ad07ecb7"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
